# üìä Customer Abandono Prediction

Este proyecto tiene como objetivo predecir la probabilidad de que un cliente abandone una empresa de telecomunicaciones utilizando modelos de machine learning. Se implement√≥ un pipeline completo de ciencia de datos: desde la limpieza y transformaci√≥n de los datos hasta la evaluaci√≥n de m√∫ltiples algoritmos con ajuste de hiperpar√°metros y t√©cnicas para tratar el desbalanceo de clases.

---

## üß† Objetivo del proyecto

Predecir si un cliente abandonar√° o no la compa√±√≠a (`Abandono`) a partir de sus caracter√≠sticas demogr√°ficas, contractuales y de facturaci√≥n. Esto permitir√° a la empresa anticipar p√©rdidas y dise√±ar estrategias de retenci√≥n.

---

## üõ†Ô∏è Herramientas utilizadas

- Python
- Pandas
- NumPy
- Scikit-learn
- imbalanced-learn (SMOTE)
- Matplotlib / Seaborn
- Jupyter Notebook
- Git / GitHub

---

## üîÑ Pipeline general

1. **Carga y exploraci√≥n de datos**
   - Revisi√≥n de valores faltantes, tipos de variables y balance de clases.
   - An√°lisis exploratorio (EDA) de variables m√°s influyentes.

2. **Preprocesamiento**
   - Normalizaci√≥n de variables num√©ricas con MinMaxScaler.
   - Codificaci√≥n One-Hot para variables categ√≥ricas.
   - Eliminaci√≥n de variables con multicolinealidad alta (VIF > 7).
   - Divisi√≥n en conjuntos de entrenamiento, validaci√≥n y prueba.

3. **Balanceo de clases**
   - Aplicaci√≥n de SMOTE sobre los datos de entrenamiento para aumentar la clase minoritaria (`Abanodno = 1`).

4. **Entrenamiento y evaluaci√≥n**
   - Comparaci√≥n entre distintos modelos: √Årbol de Decisi√≥n, Random Forest y KNN
   - Validaci√≥n cruzada con `cross_val_predict` sobre los datos balanceados.
   - Ajuste de hiperpar√°metros usando `GridSearchCV`.

5. **Pipeline final**
   - Integraci√≥n completa de preprocesamiento, balanceo y modelo en un `Pipeline` reutilizable.

---

## üìÅ Estructura del repositorio
- Codigo para limpiar la base de datos origina: ``Limpieza_datos.ipynb``
- Base de datos:``Base_datos_tratada.csv``
- Notebook principal: ``Challenge_TelecomX_2.ipynb``
- Modelos guardados: ``best_tree_model.pkl``
- Documentaci√≥n: ``Readme.md``



---

## üß™ Evaluaci√≥n de modelos

Los modelos fueron evaluados con las siguientes m√©tricas:

- Accuracy
- Precision
- Recall
- F1-Score
- Matriz de confusi√≥n

El modelo con mejor rendimiento fue **√Årbol de decisiones**, con hiperpar√°metros optimizados para buscar un mejor recall (mejorar la predicci√≥n de las personas que abandonan la empresa) y SMOTE aplicado. El pipeline logr√≥ resultados s√≥lidos en datos de validaci√≥n y test.


---

## üìå Resultados destacados

### Analisis exploratorio
Encontramos que la variable `Abandono` est√° desbalanceada, con un 73% de clientes que no abandonan y un 27% que s√≠. Esto es cr√≠tico para el modelo, ya que puede llevar a un sesgo hacia la clase mayoritaria.

![alt text](Imagenes\Distribucion_variable_respuesta.png)


Las variables n√∫mericas presentaron diferentes correlaciones con la variable de respuesta `Abandono`. La que tuvo una mayor correlaci√≥n fue `Cargo_mensual` con un coeficiente de **-0.35**, lo que indica que a mayor cargo mensual, menor es la probabilidad de abandono.

![alt text](Imagenes\Correlacion_variables_numericas.png)

De igual forma al observar las distribuciones de la variable `Cargo_mensual` con respecto a la variable de respuesta `Abandono`, se puede observar que los clientes que abandonan la empresa tienden a tener un cargo mensual m√°s bajo, lo que puede ser un indicador importante para el modelo.



- **Modelo final:** √Årbol de decisiones con pipeline completo.
- **M√©tricas (test set):**
    - Exactitud: 0.661
    - Precisi√≥n: 0.433
    - Recall: 0.879
    - F1 Score: 0.58

![alt text](Imagenes\Matriz_confucion_mejor_modelo.png)

*(Valores simulados para ilustraci√≥n. Actualizar con m√©tricas reales.)*

De igual forma es importante destacar que el las variables m√°s importantes para predecir el abandono de un cliente fueron las siguientes:

| Variable                                              | Importancia (%) |
|-------------------------------------------------------|-----------------|
| onehotencoder__Tipo_contrato_Dos a√±os                 | 46.16           |
| onehotencoder__Tipo_contrato_Un a√±o                   | 33.30           |
| onehotencoder__Metodo_pago_Cheque electr√≥nico         | 12.65           |
| remainder__Peliculas_en_streaming                     | 4.69            |
| onehotencoder__Tipo_servicio_internet_Fibra Optica    | 2.68            |
| remainder__Es_mayor_de_edad                           | 0.51            |


![alt text](Imagenes\Importancia_variables.png)

Como se puede observar se utilizaron muy pocas variables para predecir el abandono de un cliente, por lo tanto considero que todav√≠a existen muchas oportunidades de mejora en el modelo, buscando nuevas variables que puedan aportar informaci√≥n relevante relacionadas con clientes que han abandonado el servicio.

---

## üíæ C√≥mo usar el modelo

```python
import joblib
modelo = joblib.load('best_tree_model.pkl')
predicciones = modelo.predict(X_nuevo_cliente)
````
